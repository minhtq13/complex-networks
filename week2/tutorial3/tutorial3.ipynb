{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cdc8878",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b2da9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (3.4.2)\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (3.10.1)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.0-cp312-cp312-macosx_12_0_arm64.whl.metadata (31 kB)\n",
      "Collecting python-louvain\n",
      "  Downloading python-louvain-0.16.tar.gz (204 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.6/204.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (2.1.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (1.15.2)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Downloading scikit_learn-1.7.0-cp312-cp312-macosx_12_0_arm64.whl (10.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Building wheels for collected packages: python-louvain\n",
      "  Building wheel for python-louvain (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for python-louvain: filename=python_louvain-0.16-py3-none-any.whl size=9460 sha256=5171685398ca15fca6d6f6a35051b8d50d9dd4a99973c270bd8f2ca425ea6c27\n",
      "  Stored in directory: /Users/taminh/Library/Caches/pip/wheels/40/f1/e3/485b698c520fa0baee1d07897abc7b8d6479b7d199ce96f4af\n",
      "Successfully built python-louvain\n",
      "Installing collected packages: threadpoolctl, python-louvain, joblib, scikit-learn\n",
      "Successfully installed joblib-1.5.1 python-louvain-0.16 scikit-learn-1.7.0 threadpoolctl-3.6.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# BƯỚC 1: CÀI ĐẶT CÁC THƯ VIỆN CẦN THIẾT\n",
    "# ==============================================================================\n",
    "# Chạy dòng lệnh này trong terminal hoặc cell của Jupyter/Colab\n",
    "!pip3 install networkx matplotlib scikit-learn python-louvain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17666001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- EXERCISE 2: Comparing algorithms ---\n",
      "[Louvain]        => Found 4 communities.\n",
      "[Girvan-Newman]  => Found 2 communities in the first split.\n",
      "[Spectral]       => Found 2 communities as requested.\n",
      "--------------------------------------------------\n",
      "\n",
      "--- EXERCISE 3: Simulating changing communities ---\n",
      "Modularity at T=1 (clear structure): 0.6074\n",
      "Modularity at T=2 (blurrier structure):  0.5695\n",
      "--------------------------------------------------\n",
      "\n",
      "--- EXERCISE 4: Evaluating Louvain's accuracy ---\n",
      "Results with mixing parameter (mu) = 0.1:\n",
      "=> Louvain Accuracy (ARI Score): 0.9319\n",
      "Results with mixing parameter (mu) = 0.6:\n",
      "=> Louvain Accuracy (ARI Score): 0.0158\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ==============================================================================\n",
    "# STEP 2: IMPORT LIBRARIES\n",
    "# ==============================================================================\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from community import community_louvain\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "\n",
    "# ==============================================================================\n",
    "# EXERCISE 2: Compare 3 algorithms (Louvain, Girvan-Newman, Spectral)\n",
    "# ==============================================================================\n",
    "print(\"--- EXERCISE 2: Comparing algorithms ---\")\n",
    "\n",
    "# Use the classic \"Zachary's Karate Club\" graph\n",
    "G_karate = nx.karate_club_graph()\n",
    "\n",
    "# 1. Louvain Algorithm\n",
    "partition_louvain = community_louvain.best_partition(G_karate)\n",
    "num_louvain_communities = len(set(partition_louvain.values()))\n",
    "print(f\"[Louvain]        => Found {num_louvain_communities} communities.\")\n",
    "\n",
    "# 2. Girvan-Newman Algorithm\n",
    "# This algorithm returns a sequence of partitions, we take the first one\n",
    "comp_gn = nx.community.girvan_newman(G_karate)\n",
    "partition_gn = tuple(sorted(c) for c in next(comp_gn))\n",
    "num_gn_communities = len(partition_gn)\n",
    "print(f\"[Girvan-Newman]  => Found {num_gn_communities} communities in the first split.\")\n",
    "\n",
    "# 3. Spectral Clustering\n",
    "# This algorithm requires us to specify the number of clusters (k) beforehand\n",
    "k = 2  # Let's assume we want to find 2 clusters (based on the original story of the Karate graph)\n",
    "adj_matrix = nx.to_numpy_array(G_karate)\n",
    "sc = SpectralClustering(n_clusters=k, affinity='precomputed', assign_labels='kmeans', random_state=42)\n",
    "partition_spectral = sc.fit_predict(adj_matrix)\n",
    "print(f\"[Spectral]       => Found {k} communities as requested.\")\n",
    "print(\"-\" * 50 + \"\\n\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# EXERCISE 3: Simulate changing communities and track Modularity\n",
    "# ==============================================================================\n",
    "print(\"--- EXERCISE 3: Simulating changing communities ---\")\n",
    "\n",
    "# Create a graph with a clear community structure (T=1)\n",
    "sizes = [25, 25, 25]  # 3 communities, each with 25 nodes\n",
    "# Connection probability: high inside (0.7), low outside (0.02)\n",
    "probs = [[0.7, 0.02, 0.02], [0.02, 0.7, 0.02], [0.02, 0.02, 0.7]]\n",
    "G1 = nx.stochastic_block_model(sizes, probs, seed=42)\n",
    "\n",
    "# Define the ground truth communities\n",
    "ground_truth_communities = [set(range(0, 25)), set(range(25, 50)), set(range(50, 75))]\n",
    "\n",
    "# Calculate Modularity at T=1\n",
    "modularity_t1 = nx.community.modularity(G1, ground_truth_communities)\n",
    "print(f\"Modularity at T=1 (clear structure): {modularity_t1:.4f}\")\n",
    "\n",
    "# \"Blur\" community boundaries by adding random \"bridge\" edges (T=2)\n",
    "G2 = G1.copy()\n",
    "num_bridge_edges = 30\n",
    "for _ in range(num_bridge_edges):\n",
    "    # Randomly select 2 nodes from 2 different communities\n",
    "    node1 = np.random.choice(list(ground_truth_communities[0]))\n",
    "    node2 = np.random.choice(list(ground_truth_communities[1]))\n",
    "    if not G2.has_edge(node1, node2):\n",
    "        G2.add_edge(node1, node2)\n",
    "\n",
    "# Recalculate Modularity at T=2 on G2's structure, but still based on the original community partition\n",
    "modularity_t2 = nx.community.modularity(G2, ground_truth_communities)\n",
    "print(f\"Modularity at T=2 (blurrier structure):  {modularity_t2:.4f}\")\n",
    "print(\"-\" * 50 + \"\\n\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# EXERCISE 4: Evaluate accuracy using LFR data\n",
    "# ==============================================================================\n",
    "print(\"--- EXERCISE 4: Evaluating Louvain's accuracy ---\")\n",
    "\n",
    "# Experiment with 2 different levels of community \"blurriness\"\n",
    "mixing_params = [0.1, 0.6] # mu=0.1 (clear), mu=0.6 (blurry)\n",
    "\n",
    "for mu in mixing_params:\n",
    "    # 1. Create LFR benchmark graph\n",
    "    # The LFR graph is specially designed to have a known community structure\n",
    "    G_lfr = nx.LFR_benchmark_graph(n=250, tau1=3, tau2=1.5, mu=mu, average_degree=5,\n",
    "                                   min_community=20, seed=42)\n",
    "\n",
    "    # Extract the ground truth community labels from the graph\n",
    "    ground_truth_comms_lfr = {frozenset(G_lfr.nodes[v]['community']) for v in G_lfr}\n",
    "    ground_truth_labels = [0] * len(G_lfr.nodes)\n",
    "    for i, comm in enumerate(ground_truth_comms_lfr):\n",
    "        for node in comm:\n",
    "            ground_truth_labels[node] = i\n",
    "\n",
    "    # 2. Run the Louvain algorithm to find communities\n",
    "    detected_partition = community_louvain.best_partition(G_lfr)\n",
    "    detected_labels = list(detected_partition.values())\n",
    "\n",
    "    # 3. Evaluate accuracy using the Adjusted Rand Index (ARI)\n",
    "    # ARI = 1.0 is a perfect match, ARI = 0.0 is a random guess\n",
    "    ari_score = adjusted_rand_score(ground_truth_labels, detected_labels)\n",
    "    \n",
    "    print(f\"Results with mixing parameter (mu) = {mu}:\")\n",
    "    print(f\"=> Louvain Accuracy (ARI Score): {ari_score:.4f}\")\n",
    "\n",
    "print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
